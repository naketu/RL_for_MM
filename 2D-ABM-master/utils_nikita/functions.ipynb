{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4264a17",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3713d1-ed98-42e6-9add-6c5eed835a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d81927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "\n",
    "# Needed features - (Bid-Ask Spread + , Bid-Ask Volume Imbalance + , Signed Transaction Volume + )\n",
    "\n",
    "def get_order_book(info, exchange_id):\n",
    "    return info.exchanges[exchange_id].order_book\n",
    "\n",
    "def get_bids(info, exchange_id):\n",
    "    return get_order_book(info, exchange_id)['bid'].to_list()\n",
    "\n",
    "def get_asks(info, exchange_id):\n",
    "    return get_order_book(info, exchange_id)['ask'].to_list()\n",
    "\n",
    "def get_spread(info, exchange_id):\n",
    "    \n",
    "    \"\"\"\n",
    "    getting bid-ask spread as a difference between best ask and bid prices \n",
    "    for every time tick in a simulation\n",
    "    \"\"\"\n",
    "    \n",
    "    bid_ask_spread = info.spreads[exchange_id]\n",
    "    spreads = pd.DataFrame(bid_ask_spread, columns=['bid', 'ask'])\n",
    "    return list(map(lambda x: round(x, 4), (spreads['ask'] - spreads['bid'])))\n",
    "\n",
    "def get_bid_ask_volume_imbalance(info, exchange_id, depth=1000, class_division=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Bid-Ask Volume Imbalance: A signed quantity indicating the number of shares at the bid\n",
    "    minus the number of shares at the ask in the current order books.\n",
    "    \"\"\"\n",
    "    \n",
    "    bids = get_bids(info, exchange_id)\n",
    "    asks = get_asks(info, exchange_id)\n",
    "    \n",
    "    bids_qty = pd.DataFrame(bids)\n",
    "    asks_qty = pd.DataFrame(asks)\n",
    "    \n",
    "    bids_qty['trader_link'] = bids_qty['trader_link'].apply(lambda x: x.type if x else None)\n",
    "    asks_qty['trader_link'] = asks_qty['trader_link'].apply(lambda x: x.type if x else None)\n",
    "\n",
    "    bids_level = bids_qty['price'].unique()\n",
    "    bids_level = bids_level[min(depth, len(bids_level) - 1)]\n",
    "    \n",
    "    asks_level = asks_qty['price'].unique()\n",
    "    asks_level = asks_level[min(depth, len(asks_level) - 1)]\n",
    "    \n",
    "    bids_qty = bids_qty[bids_qty.price >= bids_level]\n",
    "    asks_qty = asks_qty[asks_qty.price <= asks_level]\n",
    "    \n",
    "    if class_division:\n",
    "        \n",
    "        bid_ask_volume_imbalance_list = {}\n",
    "        \n",
    "        all_bids_qty = bids_qty['qty'].sum()\n",
    "        all_asks_qty = asks_qty['qty'].sum()\n",
    "        \n",
    "        for trader_class in bids_qty['trader_link'].unique():\n",
    "            if trader_class:\n",
    "                cur_bids = bids_qty[bids_qty['trader_link'] == trader_class]['qty'].sum()\n",
    "                cur_asks = asks_qty[asks_qty['trader_link'] == trader_class]['qty'].sum()\n",
    "\n",
    "                bid_ask_volume_imbalance_list[trader_class] = (cur_bids - cur_asks)/(all_bids_qty + all_asks_qty)\n",
    "                \n",
    "            else:\n",
    "                cur_bids = bids_qty[bids_qty['trader_link'].isnull()]['qty'].sum()\n",
    "                cur_asks = asks_qty[asks_qty['trader_link'].isnull()]['qty'].sum()\n",
    "\n",
    "                bid_ask_volume_imbalance_list[trader_class] = (cur_bids - cur_asks)/(all_bids_qty + all_asks_qty)\n",
    "            \n",
    "        return bid_ask_volume_imbalance_list\n",
    "    \n",
    "    else:\n",
    "        bids_qty = bids_qty['qty'].sum()\n",
    "        asks_qty = asks_qty['qty'].sum()\n",
    "    \n",
    "        return (bids_qty - asks_qty)/(bids_qty + asks_qty)\n",
    "\n",
    "def get_transaction_volume(info, exchange_id, limit=15):\n",
    "    \n",
    "    \"\"\"\n",
    "    Signed Transaction Volume: A signed quantity indicating the number of shares bought in the\n",
    "    last 15 seconds minus the number of shares sold in the last 15 seconds.\n",
    "    \"\"\"\n",
    "    \n",
    "    transactions = pd.DataFrame(info.exchanges[exchange_id].transactions.transactions, \n",
    "                                columns=['time', 'price', 'quantity', 'side', 'trader_link'])\n",
    "    \n",
    "    time_values = sorted(transactions['time'].unique())\n",
    "    \n",
    "    limit = min(limit, len(time_values))\n",
    "    \n",
    "    if limit == 0:\n",
    "        return 0\n",
    "    \n",
    "    transactions = transactions[transactions['time'] >= time_values[-limit]]\n",
    "\n",
    "    total_buy = transactions[transactions['side'] == 'bid']['quantity'].sum()      # fulfilled bid orders - buy\n",
    "    total_sell = transactions[transactions['side'] == 'ask']['quantity'].sum()     # fulfilled ask orders - sell\n",
    "    \n",
    "    return (total_buy - total_sell) / (total_buy + total_sell)\n",
    "\n",
    "def get_all_transaction_volume(info, exchange_id, limit=15):\n",
    "    \n",
    "    \"\"\"\n",
    "    Signed Transaction Volume: A signed quantity indicating the number of shares bought in the\n",
    "    last 15 seconds minus the number of shares sold in the last 15 seconds.\n",
    "    \"\"\"\n",
    "    \n",
    "    transactions = pd.DataFrame(info.exchanges[exchange_id].transactions.transactions, \n",
    "                                columns=['time', 'price', 'quantity', 'side', 'trader_link'])\n",
    "    \n",
    "    time_values = sorted(transactions['time'].unique())\n",
    "    \n",
    "    limit = min(limit, len(time_values))\n",
    "    \n",
    "    if limit == 0:\n",
    "        return 0\n",
    "    \n",
    "    transactions = transactions[transactions['time'] >= time_values[-limit]]\n",
    "\n",
    "    total_buy = transactions[transactions['side'] == 'bid']['quantity'].sum()      # fulfilled bid orders - buy\n",
    "    total_sell = transactions[transactions['side'] == 'ask']['quantity'].sum()     # fulfilled ask orders - sell\n",
    "    \n",
    "    return (total_buy + total_sell)\n",
    "\n",
    "\"\"\"\n",
    "0 - feature, посмотреть аномалии по группам\n",
    "1 - сгенерить данные (1 конфиг) соотнести качество\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def simulation_with_data(simulator, exchange_id, n, limit=15, random_state=None, \n",
    "                         bid_ask_volume_imbalance_window = [1, 3, 5, 10], sign_transaction_volume_window = [1, 5, 10, 20],\n",
    "                         class_division=False):\n",
    "    \n",
    "    feature_list = []\n",
    "        \n",
    "    if random_state:\n",
    "        random.seed(random_state)\n",
    "    \n",
    "    for i in tqdm(range(n)):\n",
    "        \n",
    "        feature_list.append([])\n",
    "        \n",
    "        info = simulator.info\n",
    "        \n",
    "#         random.seed(random_state)\n",
    "#         print(random.random())\n",
    "        \n",
    "        simulator.simulate(1, silent=True)\n",
    "        \n",
    "        col_names = []\n",
    "        \n",
    "        \n",
    "        for w in bid_ask_volume_imbalance_window:\n",
    "            \n",
    "            bid_ask_volume_imbalance_w = get_bid_ask_volume_imbalance(info, exchange_id, depth=w, class_division=class_division)\n",
    "            \n",
    "            if class_division:\n",
    "                \n",
    "                present_classes = set(list(map(lambda x: x.type, simulator.traders)))\n",
    "                current_keys = bid_ask_volume_imbalance_w.keys()\n",
    "                \n",
    "                for cls in present_classes:\n",
    "                    \n",
    "                    if cls in current_keys:\n",
    "                        feature_list[i].append(bid_ask_volume_imbalance_w[cls])\n",
    "                        col_names.append(f\"bid_ask_volume_imbalance_{cls.replace(' ', '_')}_{w}\")\n",
    "                    else:\n",
    "                        feature_list[i].append(0)\n",
    "                        col_names.append(f\"bid_ask_volume_imbalance_{cls.replace(' ', '_')}_{w}\")                        \n",
    "            \n",
    "            else:\n",
    "                feature_list[i].append(bid_ask_volume_imbalance_w)\n",
    "                col_names.append(f\"bid_ask_volume_imbalance_{w}\")\n",
    "        \n",
    "        for w in sign_transaction_volume_window:\n",
    "            \n",
    "            sign_transaction_volume_w = get_transaction_volume(info, exchange_id, limit=w)\n",
    "            \n",
    "            feature_list[i].append(sign_transaction_volume_w)\n",
    "            col_names.append(f\"sign_transaction_volume_{w}\")\n",
    "        \n",
    "        feature_list[i].append(get_all_transaction_volume(info, exchange_id, limit=1))\n",
    "        col_names.append(\"all_transaction_volume_1\")\n",
    "    \n",
    "#     print(col_names)\n",
    "    result_df = pd.DataFrame(feature_list, columns=col_names)\n",
    "\n",
    "        \n",
    "    bid_ask_spread = get_spread(info, exchange_id)\n",
    "    \n",
    "    last_vals = len(bid_ask_spread)\n",
    "    \n",
    "    bid_ask_spread = bid_ask_spread[last_vals - n:]\n",
    "    \n",
    "    result_df['bid_ask_spread'] = bid_ask_spread\n",
    "    result_df['dividends'] = info.dividends[exchange_id][last_vals - n:] \n",
    "    result_df['price'] = info.prices[exchange_id][last_vals - n:]\n",
    "    result_df['dividends_previous_divided'] = (result_df['dividends'] / (result_df['price'] * simulator.exchanges[0].risk_free_rate).shift(1))\n",
    "    \n",
    "    fundamental_value_data = info.fundamental_value(exchange_id)\n",
    "    n_past_iterations = len(fundamental_value_data)\n",
    "    \n",
    "    result_df['fundamental_v'] = fundamental_value_data[n_past_iterations - n:]\n",
    "    \n",
    "    result_df['return_1'] = ((result_df['price'] - result_df['price'].shift(1))/result_df['price']) #*100\n",
    "    result_df['return_5'] = ((result_df['price'] - result_df['price'].shift(5))/result_df['price']) #*100\n",
    "    result_df['return_10'] = ((result_df['price'] - result_df['price'].shift(10))/result_df['price']) #*100\n",
    "    result_df['return_20'] = ((result_df['price'] - result_df['price'].shift(20))/result_df['price']) #*100\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def make_graphs(data, columns):\n",
    "    \n",
    "    colors = ['blue', 'orange', 'green', 'crimson']\n",
    "    \n",
    "    n = len(columns)\n",
    "    \n",
    "    if len(columns) % 2 == 0:\n",
    "        nrows = len(columns) // 2\n",
    "    else:\n",
    "        nrows = (len(columns) // 2) + 1\n",
    "    \n",
    "    if n == 1:\n",
    "        fig1, axs1 = plt.subplots()\n",
    "        \n",
    "    else:\n",
    "        fig1, axs1 = plt.subplots(nrows=nrows, ncols=2)\n",
    "        \n",
    "    fig1.tight_layout()\n",
    "    \n",
    "    for i in range(n):\n",
    "        axs1[i//2, i%2].plot(data[columns[i]], label=columns[i], color=plt.cm.tab10(i)) #color=colors[i%4])\n",
    "        axs1[i//2, i%2].legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def make_many_simulations(n_sim=5, n_iter=100, risk_free_rate=0.05, price=100, \n",
    "                          dividend=None, random_state=None, silent=False, market_agents=[6, 6, 6, 1],\n",
    "                          class_division=False, sim_return=False, mm_softlimit=100):\n",
    "    \n",
    "    if not dividend:\n",
    "        dividend = price * risk_free_rate\n",
    "    \n",
    "    risk_free_rate = risk_free_rate\n",
    "    price = price\n",
    "    dividend = dividend\n",
    "    \n",
    "    resulting_df = []\n",
    "    \n",
    "    simulators=[]\n",
    "    \n",
    "    for i in range(n_sim):\n",
    "        \n",
    "        random.seed(random_state)\n",
    "        \n",
    "        # print(random_state)\n",
    "    \n",
    "        assets = [Stock(dividend)]\n",
    "\n",
    "        simple_exchange = ExchangeAgent(assets[0], risk_free_rate, mean=price)\n",
    "        \n",
    "        simple_traders = [\n",
    "            *[Random(simple_exchange) for _ in range(market_agents[0])],\n",
    "            *[Chartist1D(simple_exchange) for _ in range(market_agents[1])],\n",
    "            *[Fundamentalist(simple_exchange) for _ in range(market_agents[2])],\n",
    "            *[MarketMaker1D(simple_exchange, softlimit = mm_softlimit) for _ in range(market_agents[3])]\n",
    "        ]\n",
    "        \n",
    "        # *[Universalist(market=simple_exchange) for _ in range(100)],\n",
    "\n",
    "        simple_sim = Simulator(**{\n",
    "            'assets': [assets[0]],\n",
    "            'exchanges': [simple_exchange],\n",
    "            'traders': simple_traders\n",
    "        })\n",
    "        \n",
    "        exchange_id = simple_exchange.id\n",
    "        \n",
    "        simulators.append(simple_sim)\n",
    "        \n",
    "        # bug report\n",
    "#         if i == 0:\n",
    "#             features_simulation_data = simulation_with_data(simple_sim, exchange_id, n_iter, random_state=None)\n",
    "#             make_graphs(features_simulation_data, features_simulation_data.columns)\n",
    "#             continue\n",
    "        \n",
    "#         try:\n",
    "\n",
    "        features_simulation_data = simulation_with_data(simple_sim, exchange_id, n_iter, random_state=None, class_division=class_division)\n",
    "        print(f\"--step {i + 1} of simulation results with random state {random_state}--\")\n",
    "\n",
    "        if not silent:\n",
    "            make_graphs(features_simulation_data, features_simulation_data.columns)\n",
    "\n",
    "        resulting_df.append(features_simulation_data)\n",
    "        \n",
    "        if random_state:\n",
    "            random_state = (random_state + (i + 1 + (i + 2)**2) + 100 * (i + 3)) % 11221\n",
    "        \n",
    "#         except:\n",
    "#             print('no orders bla bla')\n",
    "#             print(random_state)\n",
    "#             return\n",
    "#     plot_book(simple_sim.info, exchange_id)\n",
    "    \n",
    "    if sim_return:\n",
    "        return resulting_df, simulators\n",
    "    else:\n",
    "        return resulting_df\n",
    "\n",
    "def make_graphs_column(data, columns, figsize=[8, 10]):\n",
    "    \n",
    "    colors = ['blue', 'orange', 'green', 'crimson']\n",
    "    \n",
    "    n = len(columns)\n",
    "    \n",
    "    fig1, axs1 = plt.subplots(nrows=n, ncols=1, figsize=figsize)\n",
    "        \n",
    "    fig1.tight_layout()\n",
    "    \n",
    "    for i in range(n):\n",
    "        axs1[i].plot(data[columns[i]], label=columns[i], color=plt.cm.tab10(i)) #color=colors[i%4])\n",
    "        axs1[i].legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82887479",
   "metadata": {},
   "source": [
    "# Mean-variance analysis of trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6fe7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mean-variance analysis of trajectories\n",
    "\n",
    "def find_mean_variance(trajectories, variable):\n",
    "    n_traj = len(trajectories)\n",
    "    n_time = len(trajectories[0])\n",
    "    \n",
    "    all_trajectories = pd.DataFrame()\n",
    "    \n",
    "    rename={}\n",
    "    \n",
    "    for i in range(n_traj):\n",
    "        all_trajectories = pd.concat([all_trajectories, trajectories[i][variable]], axis=1)\n",
    "#         all_trajectories[f\"{variable}_trajectory_{i+1}\"] = trajectories[i][variable]\n",
    "        \n",
    "        rename[variable] = f\"{variable}_trajectory_{i+1}\"\n",
    "        \n",
    "        all_trajectories = all_trajectories.rename(mapper=rename, axis=1)\n",
    "    \n",
    "    all_trajectories = all_trajectories.T\n",
    "    \n",
    "    mean_vector = []\n",
    "    variance_vector = []\n",
    "    \n",
    "    for i in range(all_trajectories.shape[1]):\n",
    "        mean_vector.append((all_trajectories[i]).mean())\n",
    "        variance_vector.append((all_trajectories[i]).var())\n",
    "    \n",
    "    return mean_vector, variance_vector\n",
    "\n",
    "def draw_mean_variance(data, variable, x=250):\n",
    "    \n",
    "    mean_variance = find_mean_variance(data, variable)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    x = range(x)\n",
    "    y = mean_variance[0]\n",
    "\n",
    "\n",
    "    lower_part = y - (1.96 * np.array(mean_variance[1]) ** 0.5)\n",
    "    upper_part = y + (1.96 * np.array(mean_variance[1]) ** 0.5)\n",
    "\n",
    "    ax.plot(x,y)\n",
    "    ax.fill_between(x, lower_part, upper_part, color='b', alpha=.1)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return mean_variance\n",
    "\n",
    "def find_mean_quantile(trajectories, variable, quantile):\n",
    "    n_traj = len(trajectories)\n",
    "    n_time = len(trajectories[0])\n",
    "    \n",
    "    all_trajectories = pd.DataFrame()\n",
    "    \n",
    "    rename={}\n",
    "    \n",
    "    for i in range(n_traj):\n",
    "        all_trajectories = pd.concat([all_trajectories, trajectories[i][variable]], axis=1)\n",
    "#         all_trajectories[f\"{variable}_trajectory_{i+1}\"] = trajectories[i][variable]\n",
    "        \n",
    "        rename[variable] = f\"{variable}_trajectory_{i+1}\"\n",
    "        \n",
    "        all_trajectories = all_trajectories.rename(mapper=rename, axis=1)\n",
    "    \n",
    "    all_trajectories = all_trajectories.T\n",
    "    \n",
    "    mean_vector = []\n",
    "    lower_quantile = []\n",
    "    higher_quantile = []\n",
    "    \n",
    "    for i in range(all_trajectories.shape[1]):\n",
    "        mean_vector.append((all_trajectories[i]).mean())\n",
    "        lower_quantile.append(all_trajectories[i].quantile(q=(1-quantile), interpolation='lower'))\n",
    "        higher_quantile.append(all_trajectories[i].quantile(q=quantile, interpolation='higher'))\n",
    "    \n",
    "    return mean_vector, lower_quantile, higher_quantile\n",
    "\n",
    "def draw_mean_quantile(data, variable, quantile, x=250, title=None, y_lim=None):\n",
    "    \n",
    "    mean, lower_quantiles, higher_quantiles = find_mean_quantile(data, variable, quantile)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    x = range(x)\n",
    "    y = mean\n",
    "    \n",
    "#     if title:\n",
    "#         ax.title=title\n",
    "    \n",
    "    ax.plot(x,y, label=title)\n",
    "    \n",
    "    if y_lim:\n",
    "        ax.set_ylim([y_lim[0], y_lim[1]])\n",
    "    \n",
    "    ax.fill_between(x, lower_quantiles, higher_quantiles, color='b', alpha=.1)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return mean, lower_quantiles, higher_quantiles\n",
    "\n",
    "def draw_many_mean_quantile(dataset, variable, quantile, x=250, title=None, y_lim=None, figsize=[12, 10]):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    colors = ['b', 'g', 'r', 'y', 'm']\n",
    "    color_ind = 0\n",
    "    \n",
    "    x = range(x)\n",
    "    \n",
    "    for data in dataset:\n",
    "        mean, lower_quantiles, higher_quantiles = find_mean_quantile(data, variable, quantile)        \n",
    "        y = mean\n",
    "        \n",
    "        print(mean[-1], lower_quantiles[-1], higher_quantiles[-1])\n",
    "\n",
    "    #     if title:\n",
    "    #         ax.title=title\n",
    "\n",
    "        ax.plot(x,y, label=title[color_ind])\n",
    "\n",
    "        if y_lim:\n",
    "            ax.set_ylim([y_lim[0], y_lim[1]])\n",
    "\n",
    "        ax.fill_between(x, lower_quantiles, higher_quantiles, color=colors[color_ind], alpha=.05)\n",
    "        \n",
    "        color_ind += 1\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def draw_many_mean_variance(data, variable, labels):\n",
    "    print(f\"GRAPHS OF {variable}\")\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10,5))\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for d in data:\n",
    "        mean_variance = find_mean_variance(d, variable)\n",
    "        \n",
    "        x = range(250)\n",
    "        y = mean_variance[0]\n",
    "        \n",
    "        lower_part = y - (1.96 * np.array(mean_variance[1]) ** 0.5)\n",
    "        upper_part = y + (1.96 * np.array(mean_variance[1]) ** 0.5)\n",
    "        \n",
    "        ax[int(i>1), i%2].plot(x,y, label=labels[i])\n",
    "        ax[int(i>1), i%2].fill_between(x, lower_part, upper_part, color='b', alpha=.1)\n",
    "        \n",
    "        ax[int(i>1), i%2].legend()\n",
    "        \n",
    "        print(x, y, lower_part, upper_part)\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def draw_all_features_mean_var(data, labels):\n",
    "    variables = data[0][0].columns\n",
    "    \n",
    "    for var in variables:\n",
    "        draw_many_mean_variance(data, var, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd28d49",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "def difference_split(data, price, percentage):\n",
    "    if data > price * percentage:\n",
    "        return 1\n",
    "    elif data < -price * percentage:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def prepare_data(data, shift=5, percentage_down=0.0015, percentage_up=None, two_classes_only=False, rf_rate=0.05):\n",
    "    \n",
    "    if not percentage_up:\n",
    "        percentage_up = percentage_down\n",
    "    \n",
    "    n = data.shape[0]\n",
    "    \n",
    "    data = data.copy()\n",
    "    data['future_price'] = data['price'].shift(-shift)\n",
    "    data = data[data.index < data.shape[0] - shift]\n",
    "    \n",
    "    difference = (data['future_price'] - data['price']) / data['price']\n",
    "    \n",
    "    price_movement=[]\n",
    "    \n",
    "    for i in range(len(difference)):\n",
    "        if difference[i] > percentage_up:\n",
    "            price_movement.append(1)\n",
    "        elif difference[i] < -1 * percentage_down:\n",
    "            price_movement.append(-1)\n",
    "        else:\n",
    "            price_movement.append(0)\n",
    "        \n",
    "    data['difference'] = price_movement\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # additional normalization\n",
    "    data['bid_ask_spread_percentage'] = data['bid_ask_spread'] / data['price']\n",
    "    \n",
    "    data['fundamental_v_norm'] = data['fundamental_v'] / data['price'] - 1\n",
    "#     data['dividends_previous'] = data['dividends_previous'] \n",
    "    \n",
    "    data = data.drop(['bid_ask_spread'], axis=1)\n",
    "    \n",
    "    return data.reset_index()\n",
    "\n",
    "def prepare_huge_data(data: list(), shift=5, percentage_down=0.0015, percentage_up=None, two_classes_only=False):\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    iteration = 1\n",
    "    \n",
    "    for d in data:\n",
    "        d = prepare_data(d, shift, percentage_down, percentage_up, two_classes_only)\n",
    "        d[\"trajectory_number\"] = iteration\n",
    "        result = pd.concat([result, d])\n",
    "        \n",
    "        iteration+=1\n",
    "    \n",
    "    return result\n",
    "\n",
    "def classifier_test(test_classifier, passed_data, shift=10, percentage=0.0010, xgb=True, silent=False, x_columns=None, trajectory_test_split=0):\n",
    "    \n",
    "    # data preparation\n",
    "    \n",
    "    data_xy = prepare_huge_data(passed_data, shift=shift, percentage=percentage)\n",
    "    \n",
    "    if trajectory_test_split == 0:\n",
    "        \n",
    "        data_xy = data_xy.drop(['trajectory_number'], axis=1)\n",
    "    \n",
    "        n_iterations = max(data_xy['index'].unique())\n",
    "        train_border = n_iterations * 0.8\n",
    "\n",
    "        data_xy = data_xy[data_xy.index % shift == 0]\n",
    "\n",
    "        if not silent:\n",
    "            print('data shape -', data_xy.shape)\n",
    "\n",
    "        data_xy_train = data_xy[data_xy['index'] < train_border]\n",
    "        data_xy_test = data_xy[data_xy['index'] >= train_border]\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        n_iterations = max(data_xy['trajectory_number'].unique())\n",
    "        train_border = n_iterations * 0.8\n",
    "\n",
    "        data_xy = data_xy[data_xy.index % shift == 0]\n",
    "\n",
    "        if not silent:\n",
    "            print('data shape -', data_xy.shape)\n",
    "\n",
    "        data_xy_train = data_xy[data_xy['trajectory_number'] < train_border]\n",
    "        data_xy_test = data_xy[data_xy['trajectory_number'] >= train_border]\n",
    "        \n",
    "        data_xy_train = data_xy_train.drop(['trajectory_number'], axis=1)\n",
    "        data_xy_test = data_xy_test.drop(['trajectory_number'], axis=1)\n",
    "\n",
    "#     data_xy_train = data_xy_train.sample(frac = 1)\n",
    "\n",
    "    data_y_train = data_xy_train['difference']\n",
    "    data_x_train = data_xy_train.drop(['future_price', 'index', 'difference', 'dividends', 'price', 'fundamental_v'], axis=1) # price fundamental_v\n",
    "    \n",
    "#     data_x_train['price_m_fund'] = data_x_train['price'] - data_x_train['fundamental_v']\n",
    "\n",
    "    data_y_test = data_xy_test['difference']\n",
    "    data_x_test = data_xy_test.drop(['future_price', 'index', 'difference', 'dividends', 'price', 'fundamental_v'], axis=1) # price fundamental_v\n",
    "    \n",
    "#     data_x_test['price_m_fund'] = data_x_test['price'] - data_x_test['fundamental_v']\n",
    "    \n",
    "    if x_columns:\n",
    "        data_x_train = data_x_train[x_columns]\n",
    "        data_x_test = data_x_test[x_columns]\n",
    "    \n",
    "    if not silent:\n",
    "#         plt.title('classes distribution')\n",
    "        data_xy_train['difference'].hist()\n",
    "        data_xy_test['difference'].hist()\n",
    "        plt.show()\n",
    "    \n",
    "#     else:\n",
    "#         distribution = data_xy['difference'].value_counts()\n",
    "#         total = data_xy['difference'].count()\n",
    "        \n",
    "#         print(f\"classes distribution: \\n-1\\t{round(distribution[-1]/total, 2) * 100}%\\n0\\t{round(distribution[0]/total, 2) * 100}%\\n1\\t{round(distribution[1]*100/total, 2)}%\")\n",
    "    \n",
    "    # predictions\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = data_x_train, data_x_test, data_y_train, data_y_test\n",
    "    \n",
    "    if xgb and min(y_train)  == -1:\n",
    "        y_train += 1\n",
    "        y_test += 1\n",
    "\n",
    "    tested_model = test_classifier\n",
    "    tested_model.fit(X_train, y_train)\n",
    "\n",
    "    # training accuracy\n",
    "    predictions = tested_model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, predictions)\n",
    "    \n",
    "    if not silent:\n",
    "        print(\"TRAIN accuracy score - \", round(train_accuracy, 2)) #, recall_score(y_test, predictions))\n",
    "\n",
    "    # test accuracy\n",
    "    predictions = tested_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    if not silent:\n",
    "        print(\"TEST  accuracy score - \", round(test_accuracy, 2)) #, recall_score(y_test, predictions))\n",
    "    \n",
    "    if not silent:\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, predictions), #/confusion_matrix(y_test, predictions).sum(),\n",
    "                                    display_labels=['down', 'nothing', 'up'])\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.show()\n",
    "    \n",
    "    return tested_model, train_accuracy, test_accuracy\n",
    "\n",
    "### Functions classifications\n",
    "\n",
    "def replace_name(x):\n",
    "    return x\n",
    "\n",
    "def draw_importance_xgb(models):\n",
    "    \n",
    "    xgb_model_1, xgb_model_2, xgb_model_3, xgb_model_4 = models[0], models[1], models[2], models[3]\n",
    "    \n",
    "    xxx = pd.DataFrame(columns = replace_name(xgb_model_1.feature_names_in_))\n",
    "    xxx.loc[len(xxx.index)] = (xgb_model_1.feature_importances_)\n",
    "\n",
    "    xxy = pd.DataFrame(columns = replace_name(xgb_model_2.feature_names_in_))\n",
    "    xxy.loc[1] = (xgb_model_2.feature_importances_)\n",
    "\n",
    "    xyy = pd.DataFrame(columns = replace_name(xgb_model_3.feature_names_in_))\n",
    "    xyy.loc[2] = (xgb_model_3.feature_importances_)\n",
    "\n",
    "    yyy = pd.DataFrame(columns = replace_name(xgb_model_4.feature_names_in_))\n",
    "    yyy.loc[3] = (xgb_model_4.feature_importances_)\n",
    "\n",
    "    zzz = pd.concat([xxx, xxy, xyy, yyy])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "    zzz.T.rename({0:\"default simulation\", 1:\"simulation with no MM\", 2:\"simulation with undervalued stock\", 3:\"simulation with undervalued stock, no MM\"}, axis=1).sort_values(\"default simulation\").plot.barh(ax=ax, title=\"Importance of microstructural features for different configurations of synthetic market\") #, color=(plt.cm.Blues(0.99), plt.cm.Blues(0.8), plt.cm.Blues(0.61), plt.cm.Blues(0.42)))\n",
    "    \n",
    "    plt.plot()\n",
    "\n",
    "def new_model(name):\n",
    "    models={\n",
    "    'xgb': XGBClassifier(random_state=2114, importance_type='weight'),\n",
    "    'xgb_depth_3': XGBClassifier(random_state=2114, importance_type='weight', max_depth=3),\n",
    "    'xgb_iteration_restrict': XGBClassifier(random_state=2114, importance_type='weight', n_estimators=5),\n",
    "    'xgb_lower_lr': XGBClassifier(random_state=2114, importance_type='weight', max_depth=6, learning_rate = 0.01),\n",
    "    'xgb_l2_reg': XGBClassifier(random_state=2114, importance_type='weight', max_depth=6, reg_lambda = 100),\n",
    "    'logreg': LogisticRegression(random_state=99)\n",
    "    }\n",
    "    \n",
    "    return models[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533dc828",
   "metadata": {},
   "source": [
    "# Testing classificator in simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f5d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing classificator in simulation \n",
    "\n",
    "class FeatureCollector():\n",
    "    def __init__(self, sim_info, exchange):\n",
    "        self.info = sim_info\n",
    "        self.exchange = exchange\n",
    "        self.exchange_id = exchange.id\n",
    "    \n",
    "    def exchange_get_order_book(self):\n",
    "        return self.exchange.order_book\n",
    "\n",
    "    def exchange_get_bids(self):\n",
    "        return self.exchange_get_order_book()['bid'].to_list()\n",
    "\n",
    "    def exchange_get_asks(self):\n",
    "        return self.exchange_get_order_book()['ask'].to_list()\n",
    "\n",
    "    def exchange_get_spread(self):\n",
    "\n",
    "        \"\"\"\n",
    "        getting bid-ask spread as a difference between best ask and bid prices \n",
    "        for last tick in a simulation\n",
    "        \"\"\"\n",
    "\n",
    "        bid_ask_spread = self.exchange.spread()\n",
    "        return round(bid_ask_spread['ask'] - bid_ask_spread['bid'], 4)\n",
    "\n",
    "    def exchange_get_bid_ask_volume_imbalance(self, depth=1000):\n",
    "\n",
    "        \"\"\"\n",
    "        Bid-Ask Volume Imbalance: A signed quantity indicating the number of shares at the bid\n",
    "        minus the number of shares at the ask in the current order books.\n",
    "        \"\"\"\n",
    "\n",
    "        bids = self.exchange_get_bids()\n",
    "        asks = self.exchange_get_asks()\n",
    "\n",
    "        bids_qty = pd.DataFrame(bids)\n",
    "        asks_qty = pd.DataFrame(asks)\n",
    "\n",
    "        bids_level = bids_qty['price'].unique()\n",
    "        bids_level = bids_level[min(depth, len(bids_level) - 1)]\n",
    "\n",
    "        asks_level = asks_qty['price'].unique()\n",
    "        asks_level = asks_level[min(depth, len(asks_level) - 1)]\n",
    "\n",
    "        bids_qty = bids_qty[bids_qty.price >= bids_level]\n",
    "        asks_qty = asks_qty[asks_qty.price <= asks_level]\n",
    "\n",
    "        bids_qty = bids_qty['qty'].sum()\n",
    "        asks_qty = asks_qty['qty'].sum()\n",
    "\n",
    "        return (bids_qty - asks_qty)/(bids_qty + asks_qty)\n",
    "\n",
    "    def exchange_get_transaction_volume(self, limit=15):\n",
    "\n",
    "        \"\"\"\n",
    "        Signed Transaction Volume: A signed quantity indicating the number of shares bought in the\n",
    "        last 15 seconds minus the number of shares sold in the last 15 seconds.\n",
    "        \"\"\"\n",
    "\n",
    "        transactions = pd.DataFrame(self.exchange.transactions.transactions, \n",
    "                                    columns=['time', 'price', 'quantity', 'side', 'trader_link'])\n",
    "\n",
    "        time_values = sorted(transactions['time'].unique())\n",
    "\n",
    "        limit = min(limit, len(time_values))\n",
    "\n",
    "        if limit == 0:\n",
    "            return 0\n",
    "\n",
    "        transactions = transactions[transactions['time'] >= time_values[-limit]]\n",
    "\n",
    "        total_buy = transactions[transactions['side'] == 'bid']['quantity'].sum()      # fulfilled bid orders - buy\n",
    "        total_sell = transactions[transactions['side'] == 'ask']['quantity'].sum()     # fulfilled ask orders - sell\n",
    "\n",
    "        return (total_buy - total_sell) / (total_buy + total_sell)\n",
    "\n",
    "    def exchange_get_all_transaction_volume(self, limit=15):\n",
    "\n",
    "        \"\"\"\n",
    "        Signed Transaction Volume: A signed quantity indicating the number of shares bought in the\n",
    "        last 15 seconds minus the number of shares sold in the last 15 seconds.\n",
    "        \"\"\"\n",
    "\n",
    "        transactions = pd.DataFrame(self.exchange.transactions.transactions, \n",
    "                                    columns=['time', 'price', 'quantity', 'side', 'trader_link'])\n",
    "\n",
    "        time_values = sorted(transactions['time'].unique())\n",
    "\n",
    "        limit = min(limit, len(time_values))\n",
    "\n",
    "        if limit == 0:\n",
    "            return 0\n",
    "\n",
    "        transactions = transactions[transactions['time'] >= time_values[-limit]]\n",
    "\n",
    "        total_buy = transactions[transactions['side'] == 'bid']['quantity'].sum()      # fulfilled bid orders - buy\n",
    "        total_sell = transactions[transactions['side'] == 'ask']['quantity'].sum()     # fulfilled ask orders - sell\n",
    "\n",
    "        return (total_buy + total_sell)\n",
    "    \n",
    "    def get_features(self, limit=15, \n",
    "                         bid_ask_volume_imbalance_window = [1, 3, 5, 10], sign_transaction_volume_window = [1, 5, 10, 20]):\n",
    "        \n",
    "        exchange=self.exchange\n",
    "        info=self.info\n",
    "        \n",
    "        feature_list = {}\n",
    "        col_names = []\n",
    "\n",
    "        for w in bid_ask_volume_imbalance_window:\n",
    "\n",
    "            bid_ask_volume_imbalance_w = self.exchange_get_bid_ask_volume_imbalance(depth=w)\n",
    "            \n",
    "            feature_list[f\"bid_ask_volume_imbalance_{w}\"] = bid_ask_volume_imbalance_w\n",
    "\n",
    "        for w in sign_transaction_volume_window:\n",
    "\n",
    "            sign_transaction_volume_w = self.exchange_get_transaction_volume(limit=w)\n",
    "            \n",
    "            feature_list[f\"sign_transaction_volume_{w}\"] = sign_transaction_volume_w\n",
    "        \n",
    "        feature_list[\"all_transaction_volume_1\"] = self.exchange_get_all_transaction_volume(limit=1)\n",
    "        \n",
    "        result_df = pd.DataFrame(feature_list, index=[0])\n",
    "\n",
    "        bid_ask_spread = self.exchange_get_spread()\n",
    "\n",
    "        result_df['bid_ask_spread'] = [bid_ask_spread]\n",
    "\n",
    "        result_df['dividends'] = [exchange.dividend()]\n",
    "\n",
    "        result_df['price'] = [exchange.price()]\n",
    "\n",
    "        result_df['dividends_previous_divided'] = (result_df['dividends'] / (exchange.price() * exchange.risk_free_rate))\n",
    "    \n",
    "        fundamental_value_data = info.fundamental_value(exchange.id)[-1]\n",
    "\n",
    "        result_df['fundamental_v'] = [fundamental_value_data]\n",
    "\n",
    "        prices = info.prices[exchange.id]\n",
    "\n",
    "        if len(prices) >= 20:\n",
    "            result_df['return_1'] = ((result_df['price'] - prices[-1])/result_df['price']) #*100\n",
    "            result_df['return_5'] = ((result_df['price'] - prices[-5])/result_df['price']) #*100\n",
    "            result_df['return_10'] = ((result_df['price'] - prices[-10])/result_df['price']) #*100\n",
    "            result_df['return_20'] = ((result_df['price'] - prices[-20])/result_df['price']) #*100\n",
    "\n",
    "        elif len(prices) >= 10:\n",
    "            result_df['return_1'] = ((result_df['price'] - prices[-1])/result_df['price']) #*100\n",
    "            result_df['return_5'] = ((result_df['price'] - prices[-5])/result_df['price']) #*100\n",
    "            result_df['return_10'] = ((result_df['price'] - prices[-10])/result_df['price']) #*100\n",
    "            result_df['return_20'] = [0]\n",
    "\n",
    "        elif len(prices) >= 5:\n",
    "            result_df['return_1'] = ((result_df['price'] - prices[-1])/result_df['price']) #*100\n",
    "            result_df['return_5'] = ((result_df['price'] - prices[-5])/result_df['price']) #*100\n",
    "            result_df['return_10'] = [0]\n",
    "            result_df['return_20'] = [0]\n",
    "\n",
    "        elif len(prices) >= 1:\n",
    "            result_df['return_1'] = ((result_df['price'] - prices[-1])/result_df['price']) #*100\n",
    "            result_df['return_5'] = [0]\n",
    "            result_df['return_10'] = [0]\n",
    "            result_df['return_20'] = [0]\n",
    "\n",
    "        else:\n",
    "            result_df['return_1'] = [0]\n",
    "            result_df['return_5'] = [0]\n",
    "            result_df['return_10'] = [0]\n",
    "            result_df['return_20'] = [0]\n",
    "            \n",
    "            \n",
    "        result_df['bid_ask_spread_percentage'] = result_df['bid_ask_spread'] / result_df['price']\n",
    "        \n",
    "        result_df['fundamental_v_norm'] = result_df['fundamental_v'] / result_df['price'] - 1\n",
    "\n",
    "        return result_df.drop(['bid_ask_spread', 'dividends', 'price', 'fundamental_v'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
